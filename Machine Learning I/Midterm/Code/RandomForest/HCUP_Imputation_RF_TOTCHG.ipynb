{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from collections import Counter\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning:\n",
    "Data cleaning and preparation; admittedly, this is not the most efficient code -- but it will produce what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in dataframe\n",
    "df = pd.read_csv(\"data_train.csv\")\n",
    "\n",
    "#Steps to clean data by dropping columns where the number of empty rows is >= 445,000\n",
    "dfComplete = df.dropna(1, thresh= 445000)\n",
    "# dfComplete.shape #Results in (494932,58)\n",
    "\n",
    "#Steps to clean data by dropping row where the number of empty columns is > 0\n",
    "dfCompleteAll = dfComplete.dropna(0, how=\"any\")\n",
    "# dfCompleteAll.shape #results in a dataframe of (476155,58)\n",
    "\n",
    "# dfCompleteAll.isnull().sum() #no more nulls in the dataset\n",
    "\n",
    "y = dfCompleteAll[[\"ASOURCE\", \"ATYPE\", \"RACE\", \"TOTCHG\", \"ZIPINC_QRTL\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"The next step is to prepare variables for exploratory data analysis and feature\n",
    "selection using a random forest. \n",
    "\n",
    "Random forest does not require standardization of continuous variables or normalization\n",
    "of discrete variable. For categorical features, we will need to use pd.get_dummies or \n",
    "one hot encoding to create binary dummy variables. \n",
    "\"\"\"\n",
    "\n",
    "#First create two dataframes of int and float values to make things easier to work with \n",
    "columnNames = dfCompleteAll.columns\n",
    "dfFloat = pd.DataFrame()\n",
    "dfInt = pd.DataFrame()\n",
    "for name in columnNames:\n",
    "    if dfCompleteAll[name].dtype == float:\n",
    "        dfFloat = dfFloat.join(dfCompleteAll[name], how = \"right\")\n",
    "    else:\n",
    "        dfInt = dfInt.join(dfCompleteAll[name], how = \"right\")\n",
    "        \n",
    "#Convert all columns in DfFloat, except DISCWT, to integer values. Afterwards nominal features\n",
    "#will be one-hot encoded to create dummy variables, again we will not normalize or stadardize\n",
    "# numeric values. \n",
    "\n",
    "float_toInt = ['AGE', 'AMONTH', 'AWEEKEND', 'DIED', 'DISPUNIFORM', 'DXCCS1',\n",
    "       'DXCCS2', 'FEMALE', 'LOS', 'PAY1', 'HOSP_BEDSIZE', 'HOSP_CONTROL',\n",
    "       'HOSP_LOCTEACH']\n",
    "\n",
    "for digit in float_toInt:\n",
    "    dfFloat[digit] = dfFloat[digit].astype(int)\n",
    "    \n",
    "# In dfFloat we have the following columns and feature groupings. \n",
    "# For reference use feature_desc or call .unique() method on one of the columns\n",
    "\n",
    "# CONTINUOUS:\n",
    "dfFloatContinuous = dfFloat[[\"AGE\", \"DISCWT\"]]\n",
    "\n",
    "\n",
    "# NOMINAL:\n",
    "dfFloatNominal = dfFloat[['AMONTH', 'DISPUNIFORM', 'DXCCS1',\n",
    "       'DXCCS2', 'PAY1', 'HOSP_CONTROL','HOSP_LOCTEACH']]\n",
    "\n",
    "# BINARY & ORDINAL\n",
    "dfBinaryOrdinal = dfFloat[[\"DIED\", \"AWEEKEND\", \"FEMALE\", \"HOSP_BEDSIZE\"]]\n",
    "\n",
    "# DISCRETE\n",
    "dfDiscrete = dfFloat[[\"LOS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475155, 556)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use pd.get_dummies to turn nominal variables into dummy variables by first setting all \n",
    "#values as string, a requirement of pd.get_dummies. \n",
    "\n",
    "dfFloatNominal = dfFloatNominal.loc[:].astype(str)\n",
    "    \n",
    "dfFloatNominal = pd.get_dummies(dfFloatNominal)\n",
    "dfFloatNominal.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475155, 563)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now recreate the original dfFloat dataframe as dfFloatPreprocessed which \n",
    "# will have variables ready for feature selection with RF. Next the same thing must be down\n",
    "#with dfInt\n",
    "list_of_dataframes = [dfFloatContinuous, dfBinaryOrdinal, dfDiscrete, dfFloatNominal]\n",
    "\n",
    "dfFloatPreprocessed = pd.DataFrame()\n",
    "for frame in list_of_dataframes:\n",
    "    dfFloatPreprocessed = dfFloatPreprocessed.join(frame, how = \"right\")\n",
    "dfFloatPreprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepare dfInt for preprocessing, starting with dropping respone variables\n",
    "dfInt = dfInt.drop([\"ASOURCE\", \"ATYPE\", \"RACE\", \"TOTCHG\", \"ZIPINC_QRTL\"], axis= 1)\n",
    "\n",
    "#CMs are all binary, therefore, create a separate dataframe for these columns: \n",
    "dfCm = dfInt[['CM_AIDS', 'CM_ALCOHOL', 'CM_ANEMDEF',\n",
    "       'CM_ARTH', 'CM_BLDLOSS', 'CM_CHF', 'CM_CHRNLUNG', 'CM_COAG',\n",
    "       'CM_DEPRESS', 'CM_DM', 'CM_DMCX', 'CM_DRUG', 'CM_HTN_C', 'CM_HYPOTHY',\n",
    "       'CM_LIVER', 'CM_LYMPH', 'CM_LYTES', 'CM_METS', 'CM_NEURO', 'CM_OBESE',\n",
    "       'CM_PARA', 'CM_PERIVASC', 'CM_PSYCH', 'CM_PULMCIRC', 'CM_RENLFAIL',\n",
    "       'CM_TUMOR', 'CM_ULCER', 'CM_VALVE', 'CM_WGHTLOSS']]\n",
    "\n",
    "#Update the dfInt dataframe to a new dataframe:\n",
    "dfIntShort = dfInt.drop(['CM_AIDS', 'CM_ALCOHOL', 'CM_ANEMDEF',\n",
    "       'CM_ARTH', 'CM_BLDLOSS', 'CM_CHF', 'CM_CHRNLUNG', 'CM_COAG',\n",
    "       'CM_DEPRESS', 'CM_DM', 'CM_DMCX', 'CM_DRUG', 'CM_HTN_C', 'CM_HYPOTHY',\n",
    "       'CM_LIVER', 'CM_LYMPH', 'CM_LYTES', 'CM_METS', 'CM_NEURO', 'CM_OBESE',\n",
    "       'CM_PARA', 'CM_PERIVASC', 'CM_PSYCH', 'CM_PULMCIRC', 'CM_RENLFAIL',\n",
    "       'CM_TUMOR', 'CM_ULCER', 'CM_VALVE', 'CM_WGHTLOSS'],axis = 1)\n",
    "\n",
    "#Update the dfInt dataframe to a new dataframe:\n",
    "dfIntShort = dfInt.drop(['CM_AIDS', 'CM_ALCOHOL', 'CM_ANEMDEF',\n",
    "       'CM_ARTH', 'CM_BLDLOSS', 'CM_CHF', 'CM_CHRNLUNG', 'CM_COAG',\n",
    "       'CM_DEPRESS', 'CM_DM', 'CM_DMCX', 'CM_DRUG', 'CM_HTN_C', 'CM_HYPOTHY',\n",
    "       'CM_LIVER', 'CM_LYMPH', 'CM_LYTES', 'CM_METS', 'CM_NEURO', 'CM_OBESE',\n",
    "       'CM_PARA', 'CM_PERIVASC', 'CM_PSYCH', 'CM_PULMCIRC', 'CM_RENLFAIL',\n",
    "       'CM_TUMOR', 'CM_ULCER', 'CM_VALVE', 'CM_WGHTLOSS'],axis = 1)\n",
    "\n",
    "#Since NDX, NPR, ORPROC, TOTAL_DISC are all either Binary or Discerete variables, create a separate dataframe\n",
    "dfIntBinaryDiscrete = dfIntShort[[\"NDX\", \"NPR\", \"ORPROC\", \"TOTAL_DISC\"]]\n",
    "\n",
    "# Since DQTR, HOSPID, MDC, NIS_STRATUM, HOSP_REGION are all nominal variables, create a separate dataframe to \n",
    "#turn these into dummy variables. ALSO Drop \"KEY\" as this is the record id field: \n",
    "dfIntToDummies = dfIntShort.drop([\"KEY\", \"NDX\", \"NPR\", \"ORPROC\", \"TOTAL_DISC\"], axis= 1)\n",
    "\n",
    "#Turn values in DQTR, HOSPID, MDC, NIS_STRATUM, HOSP_REGION to string\n",
    "dfIntToDummies = dfIntToDummies.loc[:].astype(str)\n",
    "\n",
    "#Use pd.get_dummies to turn nominal string values to binary dummy variables\n",
    "dfIntToDummies = pd.get_dummies(dfIntToDummies)\n",
    "# dfIntToDummies.head()\n",
    "\n",
    "intRecombine = [dfIntToDummies, dfCm, dfIntBinaryDiscrete]\n",
    "\n",
    "dfIntPreprocessed = pd.DataFrame()\n",
    "for df in intRecombine:\n",
    "    dfIntPreprocessed = dfIntPreprocessed.join(df, how = \"right\")\n",
    "    \n",
    "dfPreprocessed = dfFloatPreprocessed.join(dfIntPreprocessed, how = \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plug these dfs back together\n",
    "dfFull = pd.concat([dfPreprocessed, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Outcome Variable Distribution\n",
    "- Total Charges (TOTCHG) is a special case, as it is continuous. We're going to break it into quartiles and use a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x11ccc7668>]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLpWx3KsOr3MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ccb5780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfFull.hist(column='TOTCHG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    475155.000\n",
       "mean      23158.186\n",
       "std       38689.596\n",
       "min         101.000\n",
       "25%        6286.000\n",
       "50%       12337.000\n",
       "75%       25708.000\n",
       "max     1461234.000\n",
       "Name: TOTCHG, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#yikes- some outliers\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x) #I hate scientific notation for manageable numbers\n",
    "dfFull.TOTCHG.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#establish our bins; they are not uniform, because total charges has some interesting outliers we can try to predict\n",
    "labels = ['1', '2', '3', '4', '5'] #just class labels we'll call 1-5\n",
    "bins = [0, 1000, 5000, 10000, 20000, 1500000]\n",
    "\n",
    "dfFull = dfFull.assign(TOTCHG_CATS = pd.cut(dfFull.TOTCHG, bins, labels=labels)) #add a new column with our cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    157053\n",
       "4    117486\n",
       "3    116383\n",
       "2     81034\n",
       "1      3199\n",
       "Name: TOTCHG_CATS, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFull.TOTCHG_CATS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5   0.331\n",
       "4   0.247\n",
       "3   0.245\n",
       "2   0.171\n",
       "1   0.007\n",
       "Name: TOTCHG_CATS, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFull.TOTCHG_CATS.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess low charges are going to be our outliers. Such is the American health care system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>DISCWT</th>\n",
       "      <th>DIED</th>\n",
       "      <th>AWEEKEND</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>HOSP_BEDSIZE</th>\n",
       "      <th>LOS</th>\n",
       "      <th>AMONTH_1</th>\n",
       "      <th>AMONTH_10</th>\n",
       "      <th>AMONTH_11</th>\n",
       "      <th>...</th>\n",
       "      <th>NDX</th>\n",
       "      <th>NPR</th>\n",
       "      <th>ORPROC</th>\n",
       "      <th>TOTAL_DISC</th>\n",
       "      <th>ASOURCE</th>\n",
       "      <th>ATYPE</th>\n",
       "      <th>RACE</th>\n",
       "      <th>TOTCHG</th>\n",
       "      <th>ZIPINC_QRTL</th>\n",
       "      <th>TOTCHG_CATS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>4.671</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>409</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>272123</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>4.671</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>209246</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>4.671</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>305474</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>4.671</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>202973</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>4.671</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>416072</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 819 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  DISCWT  DIED  AWEEKEND  FEMALE  HOSP_BEDSIZE  LOS  AMONTH_1  \\\n",
       "0   48   4.671     0         0       0             1   83         0   \n",
       "1   66   4.671     0         0       0             1   50         0   \n",
       "2   53   4.671     0         0       0             1   65         0   \n",
       "3   27   4.671     0         0       1             1   59         0   \n",
       "4   48   4.671     1         0       0             1   77         0   \n",
       "\n",
       "   AMONTH_10  AMONTH_11     ...       NDX  NPR  ORPROC  TOTAL_DISC  ASOURCE  \\\n",
       "0          0          1     ...        18    7       1         409        2   \n",
       "1          0          1     ...        18    8       0         409        2   \n",
       "2          0          1     ...        18    6       0         409        2   \n",
       "3          0          1     ...        18    4       0         409        2   \n",
       "4          0          1     ...        18    8       0         409        2   \n",
       "\n",
       "   ATYPE  RACE  TOTCHG  ZIPINC_QRTL  TOTCHG_CATS  \n",
       "0      2     1  272123            3            5  \n",
       "1      2     1  209246            1            5  \n",
       "2      2     1  305474            1            5  \n",
       "3      2     1  202973            1            5  \n",
       "4      2     1  416072            1            5  \n",
       "\n",
       "[5 rows x 819 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFull.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting\n",
    "- We are going to use a Random Forest and optimize its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dfFull.drop(['TOTCHG', 'TOTCHG_CATS'], axis=1) #have to remember to drop both or we'd be very accurate.....\n",
    "y = dfFull.TOTCHG_CATS\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Base\" Model Random Forest\n",
    "- In reality, this base model isn't at all a blind stab; we have methodically tuned Random Forests to predict other outcome variables in this dataset, and **we're starting with ideal parameters for models that imputed RACE, ASOURCE, etc.** (See the accompanying .ipynb \"HCUP_Imputation_RF_Undersample_RACE_ZIPINCQRTL\" for details).\n",
    "- We will perform **additional tuning to see if it can improve this base model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=250, max_features=100, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
       "            oob_score=True, random_state=12, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_rfc = RandomForestClassifier(n_jobs=-1,max_features=100,n_estimators=300,max_depth=250,min_samples_split=5,\n",
    "                             min_samples_leaf=1,oob_score = True,random_state=12)\n",
    "\n",
    "base_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79148742728703836"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_rfc_predictions = base_rfc.predict(X_test)\n",
    "base_rfc_accuracy = accuracy_score(y_test, base_rfc_predictions)\n",
    "base_rfc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.61      0.69       767\n",
      "          2       0.84      0.80      0.82     20435\n",
      "          3       0.72      0.75      0.73     29057\n",
      "          4       0.70      0.70      0.70     29322\n",
      "          5       0.89      0.89      0.89     39208\n",
      "\n",
      "avg / total       0.79      0.79      0.79    118789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_rfc_report = classification_report(y_test, base_rfc_predictions)\n",
    "print(base_rfc_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted TOTCHG_CAT</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual TOTCHG_CAT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>465</td>\n",
       "      <td>291</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>16382</td>\n",
       "      <td>3730</td>\n",
       "      <td>196</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2629</td>\n",
       "      <td>21773</td>\n",
       "      <td>4485</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>4670</td>\n",
       "      <td>20485</td>\n",
       "      <td>3956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>207</td>\n",
       "      <td>4070</td>\n",
       "      <td>34915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted TOTCHG_CAT    1      2      3      4      5\n",
       "Actual TOTCHG_CAT                                    \n",
       "1                     465    291      8      1      2\n",
       "2                     114  16382   3730    196     13\n",
       "3                       1   2629  21773   4485    169\n",
       "4                       1    210   4670  20485   3956\n",
       "5                       0     16    207   4070  34915"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, base_rfc_predictions, \n",
    "            rownames=['Actual TOTCHG_CAT'], colnames=['Predicted TOTCHG_CAT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice F-1 scores. And as we can see from crosstabs, when this classifier misses, it tends to miss to the classes \"next\" to it (that is, the classes of quantitative charges closest to it). This is a good classifier.\n",
    "\n",
    "**But let's see if we can improve it**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computationally, we can't handle doing a grid search on all our data. So let's try about 1/10 of the full training portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = dfFull.sample(n=30000)\n",
    "X_sample = sample.drop(['TOTCHG', 'TOTCHG_CATS'], axis=1)\n",
    "y_sample = sample.TOTCHG_CATS\n",
    "\n",
    "X_sample_train, X_sample_test, y_sample_train, y_sample_test = train_test_split(X_sample, y_sample, \n",
    "                                                                                test_size = 0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    10019\n",
       "4     7431\n",
       "3     7214\n",
       "2     5134\n",
       "1      202\n",
       "Name: TOTCHG_CATS, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The risk here is there's not enough class 1 data for the models to \"see\", and that we are optimizing this on what's really a different dataset. But, it's the best we can pull off with computational limitations! **This is why we have a \"base\" classifier (which is actually quite good) to compare to**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=250, max_features=100, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
       "            oob_score=True, random_state=12, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'min_samples_split': [2, 5, 10, 25], 'max_features': ['auto', 100, 300]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pick our params; from (bad) experience, my machine can handle about 7 different params\n",
    "param_grid = {\n",
    "    'min_samples_split': [2, 5, 10, 25],\n",
    "    'max_features': ['auto', 100, 300]\n",
    "}\n",
    "\n",
    "rfc_CV = GridSearchCV(estimator=base_rfc, param_grid=param_grid, scoring='f1_micro', \n",
    "                      n_jobs=-1, return_train_score=False)\n",
    "\n",
    "rfc_CV.fit(X_sample_train, y_sample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 300, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_CV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Best Params\" Random Forest\n",
    "- Remember, it's entirely possible this will not improve results, as the CV was biased by computational necessity.\n",
    "- Then again, it could have provided valuable insight. We'll see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=250, max_features=300, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
       "            oob_score=True, random_state=12, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X, y, test_size = 0.45, random_state = 12)\n",
    "\n",
    "rfc_tuned = RandomForestClassifier(n_jobs=-1,max_features=300,n_estimators=300,max_depth=250,min_samples_split=2,\n",
    "                             min_samples_leaf=1,oob_score = True,random_state=12)\n",
    "\n",
    "rfc_tuned.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78938285531488606"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_tuned_predictions = rfc_tuned.predict(X_test)\n",
    "rfc_tuned_accuracy = accuracy_score(y_test, rfc_tuned_predictions)\n",
    "rfc_tuned_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.62      0.68       767\n",
      "          2       0.83      0.81      0.82     20435\n",
      "          3       0.71      0.74      0.73     29057\n",
      "          4       0.70      0.70      0.70     29322\n",
      "          5       0.90      0.89      0.89     39208\n",
      "\n",
      "avg / total       0.79      0.79      0.79    118789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc_tuned_report = classification_report(y_test, rfc_tuned_predictions)\n",
    "print(rfc_tuned_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We really see no improvement. In fact, **with random variation, the \"tuned\" model is a bit worse on certain f-1 scores**. \n",
    " \n",
    "### We should stay with the more conventional base model (which is in fact quite good).\n",
    " \n",
    " **\"Base\" Model**\n",
    " \n",
    " **Accuracy: ~79.14%**\n",
    "    \n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          1       0.80      0.61      0.69       767\n",
    "          2       0.84      0.80      0.82     20435\n",
    "          3       0.72      0.75      0.73     29057\n",
    "          4       0.70      0.70      0.70     29322\n",
    "          5       0.89      0.89      0.89     39208\n",
    "\n",
    "        avg / total       0.79      0.79      0.79    118789\n",
    "\n",
    "**\"Tuned\" Model**\n",
    "\n",
    "**Accuracy: ~78.94%**\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          1       0.77      0.62      0.68       767\n",
    "          2       0.83      0.81      0.82     20435\n",
    "          3       0.71      0.74      0.73     29057\n",
    "          4       0.70      0.70      0.70     29322\n",
    "          5       0.90      0.89      0.89     39208\n",
    "\n",
    "        avg / total       0.79      0.79      0.79    118789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
