{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Cleaning\n",
    "- Admittedly, this is not the most efficient code. But it gets the job done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in dataframe\n",
    "df = pd.read_csv(\"data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DATA CLEANING STEPS\n",
    "\n",
    "#Steps to clean data by dropping columns where the number of empty rows is >= 445,000\n",
    "dfComplete = df.dropna(1, thresh= 445000)\n",
    "# dfComplete.shape #Results in (494932,58)\n",
    "\n",
    "#Steps to clean data by dropping row where the number of empty columns is > 0\n",
    "dfCompleteAll = dfComplete.dropna(0, how=\"any\")\n",
    "# dfCompleteAll.shape #results in a dataframe of (476155,58)\n",
    "\n",
    "# dfCompleteAll.isnull().sum() #no more nulls in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASOURCE</th>\n",
       "      <th>ATYPE</th>\n",
       "      <th>RACE</th>\n",
       "      <th>TOTCHG</th>\n",
       "      <th>ZIPINC_QRTL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>272123</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>209246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>305474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>202973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>416072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASOURCE  ATYPE  RACE  TOTCHG  ZIPINC_QRTL\n",
       "0        2      2     1  272123            3\n",
       "1        2      2     1  209246            1\n",
       "2        2      2     1  305474            1\n",
       "3        2      2     1  202973            1\n",
       "4        2      2     1  416072            1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract Dataframe of Variables for Classification\n",
    "y = dfCompleteAll[[\"ASOURCE\", \"ATYPE\", \"RACE\", \"TOTCHG\", \"ZIPINC_QRTL\"]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"The next step is to prepare variables for exploratory data analysis and feature\n",
    "selection using a random forest. \n",
    "\n",
    "Random forest does not require standardization of continuous variables or normalization\n",
    "of discrete variable. For categorical features, we will need to use pd.get_dummies or \n",
    "one hot encoding to create binary dummy variables. \n",
    "\"\"\"\n",
    "\n",
    "#First create two dataframes of int and float values to make things easier to work with \n",
    "columnNames = dfCompleteAll.columns\n",
    "dfFloat = pd.DataFrame()\n",
    "dfInt = pd.DataFrame()\n",
    "for name in columnNames:\n",
    "    if dfCompleteAll[name].dtype == float:\n",
    "        dfFloat = dfFloat.join(dfCompleteAll[name], how = \"right\")\n",
    "    else:\n",
    "        dfInt = dfInt.join(dfCompleteAll[name], how = \"right\")\n",
    "        \n",
    "#Convert all columns in DfFloat, except DISCWT, to integer values. Afterwards nominal features\n",
    "#will be one-hot encoded to create dummy variables, again we will not normalize or stadardize\n",
    "# numeric values. \n",
    "\n",
    "float_toInt = ['AGE', 'AMONTH', 'AWEEKEND', 'DIED', 'DISPUNIFORM', 'DXCCS1',\n",
    "       'DXCCS2', 'FEMALE', 'LOS', 'PAY1', 'HOSP_BEDSIZE', 'HOSP_CONTROL',\n",
    "       'HOSP_LOCTEACH']\n",
    "for digit in float_toInt:\n",
    "    dfFloat[digit] = dfFloat[digit].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In dfFloat we have the following columns and feature groupings. \n",
    "# For reference use feature_desc or call .unique() method on one of the columns\n",
    "\n",
    "# CONTINUOUS:\n",
    "dfFloatContinuous = dfFloat[[\"AGE\", \"DISCWT\"]]\n",
    "\n",
    "\n",
    "# NOMINAL:\n",
    "dfFloatNominal = dfFloat[['AMONTH', 'DISPUNIFORM', 'DXCCS1',\n",
    "       'DXCCS2', 'PAY1', 'HOSP_CONTROL','HOSP_LOCTEACH']]\n",
    "\n",
    "# BINARY & ORDINAL\n",
    "dfBinaryOrdinal = dfFloat[[\"DIED\", \"AWEEKEND\", \"FEMALE\", \"HOSP_BEDSIZE\"]]\n",
    "\n",
    "# DISCRETE\n",
    "dfDiscrete = dfFloat[[\"LOS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475155, 556)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use pd.get_dummies to turn nominal variables into dummy variables by first setting all \n",
    "#values as string, a requirement of pd.get_dummies. \n",
    "\n",
    "dfFloatNominal = dfFloatNominal.loc[:].astype(str)\n",
    "    \n",
    "dfFloatNominal = pd.get_dummies(dfFloatNominal)\n",
    "dfFloatNominal.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normally here, we might turn values in dfFloatContinuous to normalized, however,\n",
    "#DTs and RFs do not require this. Later if we use a different classifier, we will need\n",
    "# to standardize or normalize. \n",
    "\n",
    "#Normalization: rescaling features to a range of [0, 1], a special case of min-max scaling.\n",
    "\n",
    "#Standardization: Often more practical, center the feature columns at mean 0 with \n",
    "# standard deviation 1 so that the feature columns take the form of a normal distribution, \n",
    "#This make it easier to learn the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475155, 563)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now recreate the original dfFloat dataframe as dfFloatPreprocessed which \n",
    "# will have variables ready for feature selection with RF. Next the same thing must be down\n",
    "#with dfInt\n",
    "list_of_dataframes = [dfFloatContinuous, dfBinaryOrdinal, dfDiscrete, dfFloatNominal]\n",
    "\n",
    "dfFloatPreprocessed = pd.DataFrame()\n",
    "for frame in list_of_dataframes:\n",
    "    dfFloatPreprocessed = dfFloatPreprocessed.join(frame, how = \"right\")\n",
    "dfFloatPreprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUncomment the code below to look at values in each column to see what needs to be dropped \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare dfInt for preprocessing, starting with dropping respone variables\n",
    "dfInt = dfInt.drop([\"ASOURCE\", \"ATYPE\", \"RACE\", \"TOTCHG\", \"ZIPINC_QRTL\"], axis= 1)\n",
    "'''\n",
    "Uncomment the code below to look at values in each column to see what needs to be dropped \n",
    "'''\n",
    "\n",
    "# columnNamesInt = dfInt.columns\n",
    "\n",
    "# for name in columnNamesInt:\n",
    "#     print(name, dfInt[name].unique()) #Any values where 0,1 or ordinal e.g., DQTR we are good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CMs are all binary, therefore, create a separate dataframe for these columns: \n",
    "dfCm = dfInt[['CM_AIDS', 'CM_ALCOHOL', 'CM_ANEMDEF',\n",
    "       'CM_ARTH', 'CM_BLDLOSS', 'CM_CHF', 'CM_CHRNLUNG', 'CM_COAG',\n",
    "       'CM_DEPRESS', 'CM_DM', 'CM_DMCX', 'CM_DRUG', 'CM_HTN_C', 'CM_HYPOTHY',\n",
    "       'CM_LIVER', 'CM_LYMPH', 'CM_LYTES', 'CM_METS', 'CM_NEURO', 'CM_OBESE',\n",
    "       'CM_PARA', 'CM_PERIVASC', 'CM_PSYCH', 'CM_PULMCIRC', 'CM_RENLFAIL',\n",
    "       'CM_TUMOR', 'CM_ULCER', 'CM_VALVE', 'CM_WGHTLOSS']]\n",
    "\n",
    "#Update the dfInt dataframe to a new dataframe:\n",
    "dfIntShort = dfInt.drop(['CM_AIDS', 'CM_ALCOHOL', 'CM_ANEMDEF',\n",
    "       'CM_ARTH', 'CM_BLDLOSS', 'CM_CHF', 'CM_CHRNLUNG', 'CM_COAG',\n",
    "       'CM_DEPRESS', 'CM_DM', 'CM_DMCX', 'CM_DRUG', 'CM_HTN_C', 'CM_HYPOTHY',\n",
    "       'CM_LIVER', 'CM_LYMPH', 'CM_LYTES', 'CM_METS', 'CM_NEURO', 'CM_OBESE',\n",
    "       'CM_PARA', 'CM_PERIVASC', 'CM_PSYCH', 'CM_PULMCIRC', 'CM_RENLFAIL',\n",
    "       'CM_TUMOR', 'CM_ULCER', 'CM_VALVE', 'CM_WGHTLOSS'],axis = 1)\n",
    "\n",
    "# columnNamesInt = dfIntShort.columns\n",
    "# for name in columnNamesInt:\n",
    "#     print(name, dfIntShort[name].unique()) #Any values where 0,1 or ordinal e.g., DQTR we are good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Continue evaluating values in each column\n",
    "\n",
    "#Since NDX, NPR, ORPROC, TOTAL_DISC are all either Binary or Discerete variables, create a separate dataframe\n",
    "dfIntBinaryDiscrete = dfIntShort[[\"NDX\", \"NPR\", \"ORPROC\", \"TOTAL_DISC\"]]\n",
    "\n",
    "# Since DQTR, HOSPID, MDC, NIS_STRATUM, HOSP_REGION are all nominal variables, create a separate dataframe to \n",
    "#turn these into dummy variables. ALSO Drop \"KEY\" as this is the record id field: \n",
    "dfIntToDummies = dfIntShort.drop([\"KEY\", \"NDX\", \"NPR\", \"ORPROC\", \"TOTAL_DISC\"], axis= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Turn values in DQTR, HOSPID, MDC, NIS_STRATUM, HOSP_REGION to string\n",
    "dfIntToDummies = dfIntToDummies.loc[:].astype(str)\n",
    "\n",
    "#Use pd.get_dummies to turn nominal string values to binary dummy variables\n",
    "dfIntToDummies = pd.get_dummies(dfIntToDummies)\n",
    "# dfIntToDummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recombinet the three dataframes into a new preprocessed dataframe called dfIntPreprocessed\n",
    "intRecombine = [dfIntToDummies, dfCm, dfIntBinaryDiscrete]\n",
    "\n",
    "dfIntPreprocessed = pd.DataFrame()\n",
    "for df in intRecombine:\n",
    "    dfIntPreprocessed = dfIntPreprocessed.join(df, how = \"right\")\n",
    "    \n",
    "# dfIntPreprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>DISCWT</th>\n",
       "      <th>DIED</th>\n",
       "      <th>AWEEKEND</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>HOSP_BEDSIZE</th>\n",
       "      <th>LOS</th>\n",
       "      <th>AMONTH_1</th>\n",
       "      <th>AMONTH_10</th>\n",
       "      <th>AMONTH_11</th>\n",
       "      <th>...</th>\n",
       "      <th>CM_PULMCIRC</th>\n",
       "      <th>CM_RENLFAIL</th>\n",
       "      <th>CM_TUMOR</th>\n",
       "      <th>CM_ULCER</th>\n",
       "      <th>CM_VALVE</th>\n",
       "      <th>CM_WGHTLOSS</th>\n",
       "      <th>NDX</th>\n",
       "      <th>NPR</th>\n",
       "      <th>ORPROC</th>\n",
       "      <th>TOTAL_DISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>4.671227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>4.671227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>4.671227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>4.671227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>4.671227</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 813 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE    DISCWT  DIED  AWEEKEND  FEMALE  HOSP_BEDSIZE  LOS  AMONTH_1  \\\n",
       "0   48  4.671227     0         0       0             1   83         0   \n",
       "1   66  4.671227     0         0       0             1   50         0   \n",
       "2   53  4.671227     0         0       0             1   65         0   \n",
       "3   27  4.671227     0         0       1             1   59         0   \n",
       "4   48  4.671227     1         0       0             1   77         0   \n",
       "\n",
       "   AMONTH_10  AMONTH_11     ...      CM_PULMCIRC  CM_RENLFAIL  CM_TUMOR  \\\n",
       "0          0          1     ...                0            0         0   \n",
       "1          0          1     ...                0            0         0   \n",
       "2          0          1     ...                0            0         0   \n",
       "3          0          1     ...                0            0         0   \n",
       "4          0          1     ...                1            1         0   \n",
       "\n",
       "   CM_ULCER  CM_VALVE  CM_WGHTLOSS  NDX  NPR  ORPROC  TOTAL_DISC  \n",
       "0         0         0            1   18    7       1         409  \n",
       "1         0         0            1   18    8       0         409  \n",
       "2         0         0            1   18    6       0         409  \n",
       "3         0         0            1   18    4       0         409  \n",
       "4         0         0            1   18    8       0         409  \n",
       "\n",
       "[5 rows x 813 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine the now preprocessed dfInt and dfFloat dataframes back in a single dataframe of either discrete, continuous,\n",
    "#or binary variables. \n",
    "dfPreprocessed = dfFloatPreprocessed.join(dfIntPreprocessed, how = \"right\")\n",
    "arrayPreprocessed = np.array(dfPreprocessed)\n",
    "dfPreprocessed.head() #these are our predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute ZIPINC_QRTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#before we do anything, we need to plug our DFs back together so other features can help predict race.\n",
    "dfFull = pd.concat([dfPreprocessed, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get our X and y the same way we did with RACE\n",
    "X_zip = dfFull.drop(['ZIPINC_QRTL'], axis=1) \n",
    "y_zip = dfFull.ZIPINC_QRTL\n",
    "\n",
    "#train test split before we fudge (er, undersample) our data\n",
    "\n",
    "X_train_zip, X_test_zip, y_train_zip, y_test_zip = train_test_split(X_zip, y_zip, test_size = 0.25, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Again, we fit a \"base\" model before playing around with any of our data.**\n",
    "- This time, *use optimized settings for imputing race* (seems as good a starting point as any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=250, max_features=100, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
       "            oob_score=True, random_state=12, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zq_clf = RandomForestClassifier(n_jobs=-1,max_features=100,n_estimators=300,max_depth=250,min_samples_split=5,\n",
    "                             min_samples_leaf=1,oob_score = True, random_state=12)\n",
    "\n",
    "zq_clf.fit(X_train_zip, y_train_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62227142243810452"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zq_clf_predictions = zq_clf.predict(X_test_zip)\n",
    "zq_clf_accuracy = accuracy_score(y_test_zip, zq_clf_predictions)\n",
    "zq_clf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.71      0.69     30534\n",
      "          2       0.51      0.42      0.46     20892\n",
      "          3       0.50      0.41      0.45     27473\n",
      "          4       0.69      0.80      0.74     39890\n",
      "\n",
      "avg / total       0.61      0.62      0.61    118789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zq_clf_report = classification_report(y_test_zip, zq_clf_predictions)\n",
    "print(zq_clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Race</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21723</td>\n",
       "      <td>3511</td>\n",
       "      <td>2996</td>\n",
       "      <td>2304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5082</td>\n",
       "      <td>8845</td>\n",
       "      <td>3928</td>\n",
       "      <td>3037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3700</td>\n",
       "      <td>3409</td>\n",
       "      <td>11373</td>\n",
       "      <td>8991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2047</td>\n",
       "      <td>1611</td>\n",
       "      <td>4254</td>\n",
       "      <td>31978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Race      1     2      3      4\n",
       "Actual Race                              \n",
       "1               21723  3511   2996   2304\n",
       "2                5082  8845   3928   3037\n",
       "3                3700  3409  11373   8991\n",
       "4                2047  1611   4254  31978"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test_zip, zq_clf_predictions, rownames=['Actual Zip Inc Qrtl'], colnames=['Predicted Zip Inc Qrtl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honestly, not a bad model to start. Based on previous trial and error with this variable (in separate notebooks), this model is benefitting alot from optizimized settings.\n",
    "\n",
    "Still, let's see if we can improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    118800\n",
       "1     92350\n",
       "3     82260\n",
       "2     62956\n",
       "Name: ZIPINC_QRTL, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#observed variable counts\n",
    "y_train_zip.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#as expected from our F1 scores, 2 and 3 are under-represented.\n",
    "#let's just make all our classes equal in a dataset of 24,000 (we are going to cross val, so can't go larger)\n",
    "zip_rs = RandomUnderSampler(ratio = {1:6000, 2:6000, 3:6000, 4:6000}, random_state=12)\n",
    "\n",
    "#this time, ratio = auto means resample all except minority class\n",
    "uX_train_zip, uy_train_zip = zip_rs.fit_sample(X_train_zip, y_train_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=250, max_features=100, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
       "            oob_score=True, random_state=12, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'min_samples_split': [2, 5, 10, 25], 'max_features': ['log2', 'auto', 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we'll try a wider param grid\n",
    "zip_param_grid = {\n",
    "    'min_samples_split': [2, 5, 10, 25],\n",
    "    'max_features': ['log2', 'auto', 100]\n",
    "}\n",
    "\n",
    "#zq_clf = RandomForestClassifier(n_jobs=-1,max_features=100,n_estimators=300,max_depth=250,min_samples_split=5,\n",
    "                             #min_samples_leaf=1,oob_score = True, random_state=12)\n",
    "    \n",
    "CV_zip = GridSearchCV(estimator=zq_clf, param_grid=zip_param_grid, scoring='f1_micro', n_jobs=-1,\n",
    "                        return_train_score=False)\n",
    "\n",
    "CV_zip.fit(uX_train_zip, uy_train_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make predictions with this GridSearchCV object (which was trained on the resampled data). Then we'll compare this model to one with the same (\"ideal\") parameters on the raw training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59380919108671681"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_zip_predictions = CV_zip.predict(X_test_zip)\n",
    "CV_zip_accuracy = accuracy_score(y_test_zip, CV_zip_predictions)\n",
    "CV_zip_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.66      0.67     30534\n",
      "          2       0.43      0.52      0.47     20892\n",
      "          3       0.46      0.42      0.44     27473\n",
      "          4       0.74      0.70      0.72     39890\n",
      "\n",
      "avg / total       0.60      0.59      0.60    118789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CV_zip_report = classification_report(y_test_zip, CV_zip_predictions)\n",
    "print(CV_zip_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Zip Inc Qrtl</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Zip Inc Qrtl</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20218</td>\n",
       "      <td>5602</td>\n",
       "      <td>3320</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4377</td>\n",
       "      <td>10930</td>\n",
       "      <td>3861</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3362</td>\n",
       "      <td>5628</td>\n",
       "      <td>11660</td>\n",
       "      <td>6823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2194</td>\n",
       "      <td>3441</td>\n",
       "      <td>6525</td>\n",
       "      <td>27730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Zip Inc Qrtl      1      2      3      4\n",
       "Actual Zip Inc Qrtl                               \n",
       "1                       20218   5602   3320   1394\n",
       "2                        4377  10930   3861   1724\n",
       "3                        3362   5628  11660   6823\n",
       "4                        2194   3441   6525  27730"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test_zip, CV_zip_predictions, rownames=['Actual Zip Inc Qrtl'], colnames=['Predicted Zip Inc Qrtl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't like these results that much; pretty big hit on accuracy (3%) and f-1 scores are no better in minority classes and worse in majority classes. Here, data resampling hasn't helped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZIPINC_QRTL Cross Validation on Normal Data\n",
    "We didn't pick up much from resampling the data -- probably because these classes have a decent distribution already. So let's cross validate on a 25,000 sample of the normal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_slice = dfFull.sample(n=25000)\n",
    "X_zip_red = zip_slice.drop(['ZIPINC_QRTL'], axis=1)\n",
    "y_zip_red = zip_slice.ZIPINC_QRTL\n",
    "\n",
    "X_zip_train_red, X_zip_test_red, y_zip_train_red, y_zip_test_red = train_test_split(X_zip_red, y_zip_red,\n",
    "                                                                                   test_size = 0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=250, max_features=100, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
       "            oob_score=True, random_state=12, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'min_samples_split': [2, 5, 10, 25], 'max_features': ['log2', 'auto', 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we'll try a wider param grid\n",
    "zip_param_grid = {\n",
    "    'min_samples_split': [2, 5, 10, 25],\n",
    "    'max_features': ['log2', 'auto', 100]\n",
    "}\n",
    "\n",
    "#zq_clf = RandomForestClassifier(n_jobs=-1,max_features=100,n_estimators=300,max_depth=250,min_samples_split=5,\n",
    "                             #min_samples_leaf=1,oob_score = True, random_state=12)\n",
    "    \n",
    "CV_zip_samp = GridSearchCV(estimator=zq_clf, param_grid=zip_param_grid, scoring='f1_micro', n_jobs=-1,\n",
    "                        return_train_score=False)\n",
    "\n",
    "CV_zip_samp.fit(X_zip_train_red, y_zip_train_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 100, 'min_samples_split': 25}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check best params\n",
    "CV_zip_samp.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am wary about the best min samples being 25. We may be ramping up F1 scores for common classes. Let's find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61141183106179864"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_zip_samp_predictions = CV_zip_samp.predict(X_test_zip)\n",
    "CV_zip_samp_accuracy = accuracy_score(y_test_zip, CV_zip_samp_predictions)\n",
    "CV_zip_samp_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.72      0.67     30534\n",
      "          2       0.50      0.39      0.44     20892\n",
      "          3       0.50      0.40      0.44     27473\n",
      "          4       0.68      0.79      0.73     39890\n",
      "\n",
      "avg / total       0.60      0.61      0.60    118789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CV_zip_samp_report = classification_report(y_test_zip, CV_zip_samp_predictions)\n",
    "print(CV_zip_samp_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model is WORSE than our \"base\" model - but it also saw much less of our data** (since we had to reduce observations AND it had to be cross validated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use \"Ideal\" Params to Fit Model with Full Train Data:\n",
    "- This should be at least as good as our base model. If not, then using only 25k rows to cross validate is just giving us ideal params for 25k rows of data, not the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=250, max_features=100, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=25,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
       "            oob_score=True, random_state=12, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_model_tuned = RandomForestClassifier(n_jobs=-1,max_features=100,n_estimators=300,max_depth=250,\n",
    "                                         min_samples_split=25,min_samples_leaf=1,oob_score = True, random_state=12)\n",
    "\n",
    "zip_model_tuned.fit(X_train_zip, y_train_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62305432321174514"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_model_tuned_predictions = zip_model_tuned.predict(X_test_zip)\n",
    "zip_model_tuned_accuracy = accuracy_score(y_test_zip, zip_model_tuned_predictions)\n",
    "zip_model_tuned_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Tuned' Model Results\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.71      0.69     30534\n",
      "          2       0.51      0.42      0.46     20892\n",
      "          3       0.51      0.41      0.45     27473\n",
      "          4       0.69      0.81      0.74     39890\n",
      "\n",
      "avg / total       0.61      0.62      0.61    118789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zip_model_report = classification_report(y_test_zip, zip_model_tuned_predictions)\n",
    "print(\"'Tuned' Model Results\")\n",
    "print(zip_model_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"base\" model results**\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          1       0.67      0.71      0.69     30534\n",
    "          2       0.51      0.42      0.46     20892\n",
    "          3       0.50      0.41      0.45     27473\n",
    "          4       0.69      0.80      0.74     39890\n",
    "\n",
    "    avg / total       0.61      0.62      0.61    118789\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Zip Inc Qrtl</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Zip Inc Qrtl</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21759</td>\n",
       "      <td>3493</td>\n",
       "      <td>2989</td>\n",
       "      <td>2293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5111</td>\n",
       "      <td>8829</td>\n",
       "      <td>3904</td>\n",
       "      <td>3048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3733</td>\n",
       "      <td>3359</td>\n",
       "      <td>11232</td>\n",
       "      <td>9149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2040</td>\n",
       "      <td>1568</td>\n",
       "      <td>4090</td>\n",
       "      <td>32192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Zip Inc Qrtl      1     2      3      4\n",
       "Actual Zip Inc Qrtl                              \n",
       "1                       21759  3493   2989   2293\n",
       "2                        5111  8829   3904   3048\n",
       "3                        3733  3359  11232   9149\n",
       "4                        2040  1568   4090  32192"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test_zip, zip_model_tuned_predictions, \n",
    "            rownames=['Actual Zip Inc Qrtl'], colnames=['Predicted Zip Inc Qrtl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the narrowest of improvements with the tuned model - .01 pickup on precision in class 3 and .01 pickup on recall for class 4. This may just be random chance. Nonetheless, **it uses the full, unaltered training data, and has slighly lower-variance settings. We consider it our optimized model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optimal Settings - Classification of Variable ZIPINC_QRTL:\n",
    "\n",
    "RandomForestClassifier(n_jobs=-1,max_features=100,n_estimators=300,max_depth=250,\n",
    "                                         min_samples_split=25,min_samples_leaf=1,oob_score = True, random_state=12)\n",
    "                             \n",
    "**Accuracy: ~62.30%**\n",
    "\n",
    "**'Tuned' Model Results**\n",
    "\n",
    "            precision    recall  f1-score   support\n",
    "\n",
    "          1       0.67      0.71      0.69     30534\n",
    "          2       0.51      0.42      0.46     20892\n",
    "          3       0.51      0.41      0.45     27473\n",
    "          4       0.69      0.81      0.74     39890\n",
    "\n",
    "    avg / total       0.61      0.62      0.61    118789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
